{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzQSViQUJLk6cUf22zOADq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhruvaja/AI-Assisted-Coding/blob/main/NLP_LAB_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ASSIGNMENT 2.4"
      ],
      "metadata": {
        "id": "pjtRTr9A5MZ6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjsCcd6d8ovY",
        "outputId": "42e56c89-d5b8-4188-9af1-b4539230d287"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTx-q-xx80CV",
        "outputId": "3904196a-bd88-4041-9cf9-28d90c068fe1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOADING THE MEDICAL CORPUS"
      ],
      "metadata": {
        "id": "YR8cORLvAM9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "medical = \"\"\"The patients were diagnosed with diabetes and were prescribed medications.\n",
        "Doctors are monitoring their conditions carefully.\"\"\"\n",
        "print(medical)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhBwqCha-SzZ",
        "outputId": "24240f12-0c3b-40a7-b40a-1f77e43ffad8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The patients were diagnosed with diabetes and were prescribed medications.\n",
            "Doctors are monitoring their conditions carefully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WORD TOKENIZATION"
      ],
      "metadata": {
        "id": "NxAy3j82ARgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(medical)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1LN1dBW_aJa",
        "outputId": "2565b61b-f4be-4c1b-cedd-be7538b8c9fc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'patients',\n",
              " 'were',\n",
              " 'diagnosed',\n",
              " 'with',\n",
              " 'diabetes',\n",
              " 'and',\n",
              " 'were',\n",
              " 'prescribed',\n",
              " 'medications',\n",
              " '.',\n",
              " 'Doctors',\n",
              " 'are',\n",
              " 'monitoring',\n",
              " 'their',\n",
              " 'conditions',\n",
              " 'carefully',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SENTENCE TOKENIZATION"
      ],
      "metadata": {
        "id": "tWfTT8QEAU67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sent_tokenize(medical)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQ9K6tYE_5um",
        "outputId": "22dcec54-ff03-4ed5-bee9-b2e94daa1524"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The patients were diagnosed with diabetes and were prescribed medications.',\n",
              " 'Doctors are monitoring their conditions carefully.']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FILTERING STOP WORDS"
      ],
      "metadata": {
        "id": "WvEFjDpXPbQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VISLY-l6PfRI",
        "outputId": "485053c4-44c1-4f43-c1ec-c9d310086d8a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "filtered_list = []\n",
        "for word in words_in_quote:\n",
        "  if word.casefold() not in stop_words:\n",
        "    filtered_list.append(word)\n",
        "filtered_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz8VNFdJP3WO",
        "outputId": "a2733fbf-565d-4d7c-f886-f0a6e976132b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['patients',\n",
              " 'diagnosed',\n",
              " 'diabetes',\n",
              " 'prescribed',\n",
              " 'medications',\n",
              " '.',\n",
              " 'Doctors',\n",
              " 'monitoring',\n",
              " 'conditions',\n",
              " 'carefully',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEMMING"
      ],
      "metadata": {
        "id": "KVTuH9X3AalP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "stemmer = PorterStemmer()\n",
        "words = word_tokenize(medical)\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "stemmed_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYBTk25v_-Pq",
        "outputId": "3d32072f-39ba-42aa-b1a7-c7b9ca4fe886"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'patient',\n",
              " 'were',\n",
              " 'diagnos',\n",
              " 'with',\n",
              " 'diabet',\n",
              " 'and',\n",
              " 'were',\n",
              " 'prescrib',\n",
              " 'medic',\n",
              " '.',\n",
              " 'doctor',\n",
              " 'are',\n",
              " 'monitor',\n",
              " 'their',\n",
              " 'condit',\n",
              " 'care',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LEMMATIZATION"
      ],
      "metadata": {
        "id": "yONPs0vzAzPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = word_tokenize(medical)\n",
        "for word in words:\n",
        "    print(word,\"--->\",lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk9BefdWA1Eu",
        "outputId": "618f6ebb-2e97-4dba-e90c-3615680935f0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> The\n",
            "patients ---> patient\n",
            "were ---> were\n",
            "diagnosed ---> diagnosed\n",
            "with ---> with\n",
            "diabetes ---> diabetes\n",
            "and ---> and\n",
            "were ---> were\n",
            "prescribed ---> prescribed\n",
            "medications ---> medication\n",
            ". ---> .\n",
            "Doctors ---> Doctors\n",
            "are ---> are\n",
            "monitoring ---> monitoring\n",
            "their ---> their\n",
            "conditions ---> condition\n",
            "carefully ---> carefully\n",
            ". ---> .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GITHUB TASK"
      ],
      "metadata": {
        "id": "Q0xl0zzo5W6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOAD THE TEXT DATA"
      ],
      "metadata": {
        "id": "uj4lpVvz5ocW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"The children are playing happily in the gardens and enjoying their games.\"\"\"\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixhzILRY51i1",
        "outputId": "817e0bb7-3c5e-43f4-96d1-191264310a91"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The children are playing happily in the gardens and enjoying their games.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WORD TOKENIZATION"
      ],
      "metadata": {
        "id": "4D8TM7k27Gml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahSBVmug5rKX",
        "outputId": "7001b723-6817-4a66-a219-09db3e938e3a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'children',\n",
              " 'are',\n",
              " 'playing',\n",
              " 'happily',\n",
              " 'in',\n",
              " 'the',\n",
              " 'gardens',\n",
              " 'and',\n",
              " 'enjoying',\n",
              " 'their',\n",
              " 'games',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SENTENCE TOKENIZATION"
      ],
      "metadata": {
        "id": "QFoSg3Dr7VzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sent_tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNGv9aY85brZ",
        "outputId": "0d65c768-46bb-405b-accc-fe279b016bf1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The children are playing happily in the gardens and enjoying their games.']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FILTERING STOP WORDS"
      ],
      "metadata": {
        "id": "7H72N1Il7tL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "filtered_list = []\n",
        "for word in words_in_quote:\n",
        "  if word.casefold() not in stop_words:\n",
        "    filtered_list.append(word)\n",
        "filtered_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCRbk_Q277Iv",
        "outputId": "6cf25280-fc0b-4ce2-c076-73888163e36a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['patients',\n",
              " 'diagnosed',\n",
              " 'diabetes',\n",
              " 'prescribed',\n",
              " 'medications',\n",
              " '.',\n",
              " 'Doctors',\n",
              " 'monitoring',\n",
              " 'conditions',\n",
              " 'carefully',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEMMING"
      ],
      "metadata": {
        "id": "20NEM8dB8DRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "stemmer = PorterStemmer()\n",
        "words = word_tokenize(text)\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "stemmed_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9mybIGK8AY7",
        "outputId": "f27f06ad-a3a3-4007-dbd1-f2c149867611"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'children',\n",
              " 'are',\n",
              " 'play',\n",
              " 'happili',\n",
              " 'in',\n",
              " 'the',\n",
              " 'garden',\n",
              " 'and',\n",
              " 'enjoy',\n",
              " 'their',\n",
              " 'game',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LEMMATIZATION"
      ],
      "metadata": {
        "id": "suNwtjUw8Rgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = word_tokenize(text)\n",
        "for word in words:\n",
        "    print(word,\"--->\",lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4OfI6X88T7f",
        "outputId": "c295c4cc-7854-4e4b-a1c3-10728ce6cad1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> The\n",
            "children ---> child\n",
            "are ---> are\n",
            "playing ---> playing\n",
            "happily ---> happily\n",
            "in ---> in\n",
            "the ---> the\n",
            "gardens ---> garden\n",
            "and ---> and\n",
            "enjoying ---> enjoying\n",
            "their ---> their\n",
            "games ---> game\n",
            ". ---> .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEXT PREPROCESSING TASK IN PPT"
      ],
      "metadata": {
        "id": "_E4VsJvV8dPm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOAD THE TEXT DATA"
      ],
      "metadata": {
        "id": "eEU-8dH08wvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = \"NLP models are transforming the world rapidly!\"\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV0I8ROA8hvP",
        "outputId": "a35810b6-8451-4857-a1e2-11d04f44f401"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLP models are transforming the world rapidly!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WORD TOKENIZATION"
      ],
      "metadata": {
        "id": "MngCdD2S84pa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "words_in_quote = word_tokenize(data)\n",
        "words_in_quote\n",
        "word_tokenize(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRVMezL087Dn",
        "outputId": "62628766-d12b-44a7-b7f4-2d316a8b7f91"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NLP', 'models', 'are', 'transforming', 'the', 'world', 'rapidly', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SENTENCE TOKENIZATION"
      ],
      "metadata": {
        "id": "Og-9XH-s9KcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sent_tokenize(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ko_8wjNE9Mv6",
        "outputId": "a24006c9-12d7-4c82-8440-18ba911c41d1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NLP models are transforming the world rapidly!']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FILTERING STOP WORDS"
      ],
      "metadata": {
        "id": "k7cgHDQV9V7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "filtered_list = []\n",
        "for word in words_in_quote:\n",
        "  if word.casefold() not in stop_words:\n",
        "    filtered_list.append(word)\n",
        "filtered_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKwvXM9q9Yao",
        "outputId": "6bca01f9-db95-4edb-8e3b-a841a4294333"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NLP', 'models', 'transforming', 'world', 'rapidly', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEMMING"
      ],
      "metadata": {
        "id": "CJzoSHln96r5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "stemmer = PorterStemmer()\n",
        "words = word_tokenize(data)\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "stemmed_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_Ytaeqo98B3",
        "outputId": "5ee6eab5-d173-45cc-e873-b2e75dcfac74"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nlp', 'model', 'are', 'transform', 'the', 'world', 'rapidli', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LEMMATIZATION"
      ],
      "metadata": {
        "id": "70gyE43v-AVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = word_tokenize(text)\n",
        "for word in words:\n",
        "    print(word,\"--->\",lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swO-eQ0U-B5R",
        "outputId": "4eaf6f43-951a-47b1-ba19-ec85f2455d99"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> The\n",
            "children ---> child\n",
            "are ---> are\n",
            "playing ---> playing\n",
            "happily ---> happily\n",
            "in ---> in\n",
            "the ---> the\n",
            "gardens ---> garden\n",
            "and ---> and\n",
            "enjoying ---> enjoying\n",
            "their ---> their\n",
            "games ---> game\n",
            ". ---> .\n"
          ]
        }
      ]
    }
  ]
}